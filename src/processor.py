import os
import json
import logging
from concurrent.futures import ThreadPoolExecutor
from typing import List
from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_fixed
from collector import NewsItem

# Setup Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIProcessor:
    def __init__(self):
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL")
        )
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o")

    def _get_prompt(self, item: NewsItem) -> str:
        return f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI ç§‘æŠ€æ–°é—»ç¼–è¾‘ã€‚è¯·åˆ†æžä»¥ä¸‹æ–°é—»æ¡ç›®ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºæ·±åº¦åˆ†æžç»“æžœã€‚

        æ–°é—»æ ‡é¢˜: {item.title}
        æ¥æº: {item.source}
        å†…å®¹ç‰‡æ®µ: {item.content_snippet}

        ä»»åŠ¡è¦æ±‚ï¼š
        1. zh_title: å°†æ ‡é¢˜ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚å¦‚æžœåŽŸæ ‡é¢˜å·²ç»æ˜¯ä¸­æ–‡ï¼Œç›´æŽ¥ä¿ç•™ã€‚ç¡®ä¿ä¿¡è¾¾é›…ï¼Œå¸å¼•äººä½†ä¸è¿‡åˆ†æ ‡é¢˜å…šã€‚
        2. summary: ç”¨ä¸­æ–‡å†™ä¸€æ®µ 100-150 å­—çš„è¯¦ç»†æ‘˜è¦ã€‚å¿…é¡»åŒ…å«æ ¸å¿ƒäº‹å®žã€æŠ€æœ¯åŽŸç†ï¼ˆå¦‚æœ‰ï¼‰å’ŒèƒŒæ™¯æ„ä¹‰ã€‚ä¸è¦å†™ç©ºè¯ã€‚
        3. key_points: æå– 3-5 ä¸ªæ ¸å¿ƒè¦ç‚¹ (Bullet Points)ï¼Œä»¥æ•°ç»„å½¢å¼è¿”å›žã€‚æ¯ä¸ªè¦ç‚¹åº”åŒ…å«å…·ä½“ç»†èŠ‚ï¼ˆå¦‚æ•°æ®ã€æ€§èƒ½æå‡å¹…åº¦ã€å…³é”®äººç‰©ç­‰ï¼‰ã€‚
        4. category: ä»Ž ["ðŸš€ æ¨¡åž‹å‘å¸ƒ", "ðŸ› ï¸ å·¥å…·åº”ç”¨", "ðŸ”¬ å­¦æœ¯ç ”ç©¶", "ðŸ’¼ è¡Œä¸šåŠ¨æ€", "ðŸ“± ç¤¾äº¤åª’ä½“", "ðŸ‘” å¤§ä½¬è§‚ç‚¹"] ä¸­é€‰æ‹©æœ€åˆé€‚çš„ä¸€ä¸ªã€‚
        5. tags: æå– 3-5 ä¸ªè‹±æ–‡æ ‡ç­¾ (å¦‚ LLM, RAG, Agent, CV, Transformer)ã€‚
        6. score: æ ¹æ®æ–°é—»å¯¹ AI é¢†åŸŸçš„é‡è¦æ€§/åˆ›æ–°æ€§æ‰“åˆ† (1-5 çš„æ•´æ•°)ã€‚5åˆ†ä»£è¡¨é‡å¤§çªç ´æˆ–è¡Œä¸šå¤§äº‹ä»¶ã€‚

        è¾“å‡ºæ ¼å¼ (JSON):
        {{
            "zh_title": "...",
            "summary": "...",
            "key_points": ["è¦ç‚¹1...", "è¦ç‚¹2..."],
            "category": "...",
            "tags": ["Tag1", "Tag2"],
            "score": 3
        }}
        """

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
    def process_item(self, item: NewsItem) -> NewsItem:
        if not item.title:
            return item

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant that outputs strict JSON."},
                    {"role": "user", "content": self._get_prompt(item)}
                ],
                response_format={"type": "json_object"},
                temperature=0.3
            )
            
            content = response.choices[0].message.content
            if content.startswith("```json"):
                content = content[7:-3]
            
            data = json.loads(content)
            
            item.zh_title = data.get("zh_title", item.title)
            item.summary = data.get("summary", "")
            item.key_points = data.get("key_points", []) # Capture bullet points
            item.category = data.get("category", "å…¶ä»–")
            item.tags = data.get("tags", [])
            item.ai_score = data.get("score", 3)
            
        except Exception as e:
            logger.error(f"Failed to process item {item.title}: {e}")
            item.zh_title = item.title
            item.summary = "AI å¤„ç†å¤±è´¥ï¼Œè¯·æŸ¥çœ‹åŽŸæ–‡ã€‚"
            item.key_points = []
            item.category = "âš ï¸ æœªåˆ†ç±»"
            item.ai_score = 1
            
        return item

    def process_batch(self, items: List[NewsItem]) -> List[NewsItem]:
        logger.info(f"Processing {len(items)} items with AI...")
        processed_items = []
        with ThreadPoolExecutor(max_workers=5) as executor:
            results = executor.map(self.process_item, items)
            processed_items = list(results)
        
        # Sort by Score
        processed_items.sort(key=lambda x: x.ai_score, reverse=True)
        return processed_items
